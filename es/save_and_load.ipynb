{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1l8bWGmIJuQa"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.ss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
        },
        "colab_type": "code",
        "id": "CPSnXS88KFEo"
      },
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "89xNCIO5hiCj"
      },
      "source": [
        "# Guarde y cargue un modelo usando una estrategia de distribución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ejs4QVxIdAm"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/save_and_load\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\"> Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\"> Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\"> Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/distribute/save_and_load.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\"> Descargar cuaderno</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A0lG6qgThxAS"
      },
      "source": [
        "## Visión general\n",
        "\n",
        "Es común guardar y cargar un modelo durante el entrenamiento. Hay dos conjuntos de API para guardar y cargar un modelo de keras: una API de alto nivel y una API de bajo nivel. Este tutorial demuestra cómo puede usar las API de SavedModel cuando usa `tf.distribute.Strategy` . Para obtener más información sobre SavedModel y la serialización en general, lea la [guía del modelo guardado](../../guide/saved_model.ipynb) y la [guía de serialización del modelo Keras](../../guide/keras/save_and_serialize.ipynb) . Comencemos con un ejemplo simple: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FITHltVKQ4eZ"
      },
      "source": [
        "Importar dependencias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "RWG5HchAiOrZ"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qqapWj98ptNV"
      },
      "source": [
        "Prepare los datos y el modelo usando `tf.distribute.Strategy` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "yrYiAf_ziRyw"
      },
      "outputs": [

      ],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def get_data():\n",
        "  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "\n",
        "  BATCH_SIZE_PER_REPLICA = 64\n",
        "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "  return train_dataset, eval_dataset\n",
        "\n",
        "def get_model():\n",
        "  with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qmU4Y3feS9Na"
      },
      "source": [
        "Entrena el modelo: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "zmGurbJmS_vN"
      },
      "outputs": [

      ],
      "source": [
        "model = get_model()\n",
        "train_dataset, eval_dataset = get_data()\n",
        "model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L01wjgvRizHS"
      },
      "source": [
        "## Guarde y cargue el modelo\n",
        "\n",
        "Ahora que tiene un modelo simple con el que trabajar, echemos un vistazo a las API de guardar / cargar. Hay dos conjuntos de API disponibles:\n",
        "\n",
        "- High level keras `model.save` and 1`tf.keras.models.load_model`\n",
        "- Low level `tf.saved_model.save` and `tf.saved_model.load` 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FX_IF2F1tvFs"
      },
      "source": [
        "### Las API de Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O8xfceg4Z3H_"
      },
      "source": [
        "A continuación, se muestra un ejemplo de cómo guardar y cargar un modelo con las API de Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "LYOStjV5knTQ"
      },
      "outputs": [

      ],
      "source": [
        "keras_model_path = \"/tmp/keras_save\"\n",
        "model.save(keras_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yvQIdQp3zNMp"
      },
      "source": [
        "Restaurar el modelo sin `tf.distribute.Strategy` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "WrXAAVtrzRgv"
      },
      "outputs": [

      ],
      "source": [
        "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
        "restored_keras_model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYAnskzorda-"
      },
      "source": [
        "Después de restaurar el modelo, puede continuar entrenando en él, incluso sin necesidad de llamar a `compile()` nuevamente, ya que ya está compilado antes de guardarlo. El modelo se guarda en el formato proto estándar `SavedModel` TensorFlow. Para obtener más información, consulte [la guía de formato `saved_model`](../../guide/saved_model.ipynb) .\n",
        "\n",
        "Ahora para cargar el modelo y entrenarlo usando un `tf.distribute.Strategy` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "wROPrJaAqBQz"
      },
      "outputs": [

      ],
      "source": [
        "another_strategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
        "with another_strategy.scope():\n",
        "  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n",
        "  restored_keras_model_ds.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PdiiPmL5tQk5"
      },
      "source": [
        "Como puede ver, la carga funciona como se esperaba con `tf.distribute.Strategy` . La estrategia utilizada aquí no tiene que ser la misma estrategia utilizada antes de guardar. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3CrXIbmFt0f6"
      },
      "source": [
        "### Las API `tf.saved_model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HtGzPp6et4Em"
      },
      "source": [
        "Ahora echemos un vistazo a las API de nivel inferior. Guardar el modelo es similar a la API de keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "4y6T31APuCqK"
      },
      "outputs": [

      ],
      "source": [
        "model = get_model()  # get a fresh model\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q1QNRYcwuRll"
      },
      "source": [
        "La carga se puede realizar con `tf.saved_model.load()` . Sin embargo, dado que es una API que se encuentra en el nivel inferior (y, por lo tanto, tiene una gama más amplia de casos de uso), no devuelve un modelo de Keras. En cambio, devuelve un objeto que contiene funciones que se pueden usar para hacer inferencias. Por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "aaEKqBSPwAuM"
      },
      "outputs": [

      ],
      "source": [
        "DEFAULT_FUNCTION_KEY = \"serving_default\"\n",
        "loaded = tf.saved_model.load(saved_model_path)\n",
        "inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x65l7AaHUZCA"
      },
      "source": [
        "El objeto cargado puede contener múltiples funciones, cada una asociada con una clave. El `\"serving_default\"` es la clave predeterminada para la función de inferencia con un modelo Keras guardado. Para hacer una inferencia con esta función: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "5Ore5q8-UjW1"
      },
      "outputs": [

      ],
      "source": [
        "predict_dataset = eval_dataset.map(lambda image, label: image)\n",
        "for batch in predict_dataset.take(1):\n",
        "  print(inference_func(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "osB1LY8WwUJZ"
      },
      "source": [
        "También puede cargar y hacer inferencias de manera distribuida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "iDYvu12zYTmT"
      },
      "outputs": [

      ],
      "source": [
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n",
        "\n",
        "  dist_predict_dataset = another_strategy.experimental_distribute_dataset(\n",
        "      predict_dataset)\n",
        "\n",
        "  # Calling the function in a distributed manner\n",
        "  for batch in dist_predict_dataset:\n",
        "    another_strategy.run(inference_func,args=(batch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hWGSukoyw3fF"
      },
      "source": [
        "Llamar a la función restaurada es solo un pase hacia adelante en el modelo guardado (predecir). ¿Qué sucede si desea continuar entrenando la función cargada? ¿O incrustar la función cargada en un modelo más grande? Una práctica común es envolver este objeto cargado en una capa de Keras para lograr esto. Afortunadamente, [TF Hub](https://www.tensorflow.org/hub) tiene [hub.KerasLayer](https://github.com/tensorflow/hub/blob/master/tensorflow_hub/keras_layer.py) para este propósito, que se muestra aquí:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "clfk3hQoyKu6"
      },
      "outputs": [

      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def build_model(loaded):\n",
        "  x = tf.keras.layers.Input(shape=(28, 28, 1), name='input_x')\n",
        "  # Wrap what's loaded to a KerasLayer\n",
        "  keras_layer = hub.KerasLayer(loaded, trainable=True)(x)\n",
        "  model = tf.keras.Model(x, keras_layer)\n",
        "  return model\n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  model = build_model(loaded)\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "  model.fit(train_dataset, epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oe1z_OtSJlu2"
      },
      "source": [
        "Como puede ver, `hub.KerasLayer` envuelve el resultado cargado desde `tf.saved_model.load()` en una capa de Keras que se puede usar para construir otro modelo. Esto es muy útil para el aprendizaje por transferencia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KFDOZpK5Wa3W"
      },
      "source": [
        "### ¿Qué API debo utilizar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GC6GQ9HDLxD6"
      },
      "source": [
        "Para guardar, si está trabajando con un modelo de Keras, casi siempre se recomienda utilizar la API `model.save()` Keras. Si lo que está guardando no es un modelo de Keras, entonces la API de nivel inferior es su única opción.\n",
        "\n",
        "Para la carga, la API que utilice depende de lo que desee obtener de la API de carga. Si no puede (o no desea) obtener un modelo de Keras, utilice `tf.saved_model.load()` . De lo contrario, use `tf.keras.models.load_model()` . Tenga en cuenta que puede recuperar un modelo de Keras solo si guardó un modelo de Keras.\n",
        "\n",
        "Es posible mezclar y combinar las API. Puede guardar un modelo de Keras con `model.save` y cargar un modelo que no sea de Keras con la API de bajo nivel, `tf.saved_model.load` . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "Ktwg2GwnXE8v"
      },
      "outputs": [

      ],
      "source": [
        "model = get_model()\n",
        "\n",
        "# Saving the model using Keras's save() API\n",
        "model.save(keras_model_path) \n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "# Loading the model using lower level API\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(keras_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJTWOnC9iuA3"
      },
      "source": [
        "### Advertencias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tzog2ti7YYgy"
      },
      "source": [
        "Un caso especial es cuando tiene un modelo de Keras que no tiene entradas bien definidas. Por ejemplo, un modelo secuencial se puede crear sin ninguna forma de entrada ( `Sequential([Dense(3), ...]` ). Los modelos subclasificados tampoco tienen entradas bien definidas después de la inicialización. En este caso, debe seguir con el API de nivel inferior tanto para guardar como para cargar, de lo contrario, obtendrá un error.\n",
        "\n",
        "Para verificar si su modelo tiene entradas bien definidas, simplemente verifique si `model.inputs` es `None` . Si no es `None` , todo está bien. Las formas de entrada se definen automáticamente cuando el modelo se usa en `.fit` , `.evaluate` , `.predict` , o cuando se llama al modelo ( `model(inputs)` ).\n",
        "\n",
        "Aquí hay un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
        },
        "colab_type": "code",
        "id": "gurSIbDFjOBc"
      },
      "outputs": [

      ],
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  output_name = 'output_layer'\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SubclassedModel, self).__init__()\n",
        "    self._dense_layer = tf.keras.layers.Dense(\n",
        "        5, dtype=tf.dtypes.float32, name=self.output_name)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self._dense_layer(inputs)\n",
        "\n",
        "my_model = SubclassedModel()\n",
        "# my_model.save(keras_model_path)  # ERROR! \n",
        "tf.saved_model.save(my_model, saved_model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "save_and_load.ipynb",
      "private_outputs": true,
      "provenance": [

      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
